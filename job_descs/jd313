The Job

  To develop robust processes to ingest huge amounts of data from disparate systems, and build processes that transform and use that data.
  Core technology used is Apache Spark on top of HDFS, and development is primarily in Java. 
  With a strong interest in data processing and data science: 

The Talent

  At least 5 years of software development experience
  At least 3 years experience working with Java
  Knowledge of recent Java language features, such as lambdas, streams, and futures
  Experience with Maven, Git, writing and maintaining integration tests
  Some familiarity with Linux and bash
  Knowledge of SQL or an SQL-inspired dialect such as HQL
  Expertise on Hadoop Big data clusters and tech: Spark, Kafka, HDFS, etc
  Familiar with Jenkins and Ansible
  Familiar with Jira or a similar issue-tracking system

Nice to have

  Web development fundamentals (HTML, Javascript, jQuery, ReactJS, etc)
  Some interest in finance &amp; financial markets

Next Steps

  Interested applicants kindly forward the latest copy of your resume in MS Word format  (with details of your last drawn and expected salaries) to waicharng.chong@adecco.com
  All shortlisted candidates will be notified!

Chong Wai Charng (R1652634)
Consultant – Staffing Division
Email: waicharng.chong@adecco.com